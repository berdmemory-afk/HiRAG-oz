# Configuration for Context Manager

[embedding]
api_url = "https://chutes-intfloat-multilingual-e5-large.chutes.ai/v1/embeddings"
api_token = "cpk_37140d33ae1f4a77ba9980e4fc78a624.25e244203d585ca49b14a4bee55bfda2.MFjdI47zPJZVD16144TNJWv8xlJxBRil"
batch_size = 32
timeout_secs = 30
max_retries = 3
cache_enabled = true
cache_ttl_secs = 3600
cache_size = 1000
tls_enabled = true
tls_verify = true

[vector_db]
url = "http://localhost:6334"
# api_key = "optional_api_key"
collection_prefix = "contexts"
vector_size = 1024
distance = "Cosine"
timeout_secs = 10
tls_enabled = false
tls_verify = true

[hirag]
l1_size = 10
l2_size = 100
l3_enabled = true
max_context_tokens = 4000
relevance_threshold = 0.7
token_estimator = { type = "CharacterBased", chars_per_token = 4.0 }
retrieval_strategy = { l1_allocation = 0.3, l2_allocation = 0.4, l3_allocation = 0.3, min_contexts_per_level = 1 }
ranking_weights = { similarity_weight = 0.5, recency_weight = 0.2, level_weight = 0.2, frequency_weight = 0.1 }
gc_enabled = false
gc_interval_secs = 300
l2_ttl_secs = 3600
l3_ttl_secs = 86400

[protocol]
version = "1.0.0"
codec = "json"
max_message_size_mb = 10

[logging]
level = "info"
format = "json"

[server]
port = 8081
host = "0.0.0.0"
max_body_size_mb = 10
[token_budget]
# Token budget configuration for â‰¤8k token enforcement
# Based on brainstorming.md specifications
system_tokens = 700          # System/Instructions: 600-800 tokens
running_brief = 1200         # Running Brief: 1,000-1,500 tokens
recent_turns = 450           # Recent Turns: 300-600 tokens
retrieved_context = 3750     # Retrieved Context: 3,000-4,500 tokens (8-12 snippets)
completion = 1000            # Completion: 800-1,200 tokens
max_total = 8000             # Maximum total tokens per turn

[vision]
# Vision API configuration for DeepSeek OCR integration
service_url = "http://localhost:8080"  # DeepSeek service endpoint (stub)
timeout_ms = 5000                       # Request timeout in milliseconds
max_regions_per_request = 16            # Maximum regions per decode request
default_fidelity = "10x"                # Default fidelity level (20x, 10x, 5x, 1x)

[facts]
# Facts store configuration for neuro-symbolic reasoning
collection_name = "facts"               # Qdrant collection name for facts
dedup_enabled = true                    # Enable hash-based deduplication
confidence_threshold = 0.8              # Minimum confidence for fact insertion
max_facts_per_query = 100               # Maximum facts returned per query
